{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google News URL Scraping and Sentiment Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FDDI-CentOS/data/blob/master/Google_News_URL_Scraping_and_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm07xEtxG__7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google News Search and Sentiment Analysis\n",
        "# Run installs once for package prep then comment out to reduce overhead\n",
        "# !pip install textblob bs4 requests \n",
        "# !pip install pydrive\n",
        "# djarguello@ 8-17-19\n",
        "\n",
        "from textblob import TextBlob\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "\n",
        "# Initialize lists: Update keywords to tune results\n",
        "other_bets = ['waymo',\n",
        "              'verily',\n",
        "              'access',\n",
        "              'deepmind',\n",
        "              'calico',\n",
        "              'capitalg',\n",
        "              'googleventures', \n",
        "              'sidewalk', \n",
        "              'wing',\n",
        "              'loon',\n",
        "              'jigsaw',\n",
        "              'makani',\n",
        "              'x']\n",
        "\n",
        "keywords = ['Waymo+AND+lyft',\n",
        "            'verily','access',\n",
        "            'deepmind',\n",
        "            'calico',\n",
        "            'capitalg',\n",
        "            'googleventures', \n",
        "            'sidewalk', \n",
        "            'wing',\n",
        "            'loon',\n",
        "            'jigsaw',\n",
        "            'makani',\n",
        "            'x']\n",
        "\n",
        "# Analysis Class Object\n",
        "class Analysis:\n",
        "  def __init__(self, term):\n",
        "      self.term = term\n",
        "      self.subjectivity = 0\n",
        "      self.sentiment = 0\n",
        "      self.url = 'https://www.google.com/search?q={0}&source=lmns&tbm=nws&tbs=qdr:m'.format(self.term) # Google News Monthly Feed\n",
        "      \n",
        "  def run(self):\n",
        "    file = []\n",
        "    response = requests.get(self.url)\n",
        "    # Print(response.text) # debugging / review response results\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    headline_results = soup.find_all('div', class_='st')\n",
        "    for h in headline_results:\n",
        "      temp = str(h)\n",
        "      temp = re.sub('\\ |\\?|\\.|\\!|\\/|\\;|\\:', ' ', temp)\n",
        "      temp = re.sub('\\<.*?>', ' ', temp)\n",
        "      temp = re.sub('\\xa0','',temp)\n",
        "      temp = re.sub('\\s{2,}', ' ', temp) # Test code\n",
        "      temp = temp.strip('<div class=\"st\">')\n",
        "      file.append(temp) \n",
        "      blob = TextBlob(h.get_text())\n",
        "      self.sentiment += blob.sentiment.polarity / len(headline_results)\n",
        "      self.subjectivity += blob.sentiment.subjectivity / len(headline_results)\n",
        "    return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKHmtYqUZEY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analysis Function Run for Each Bet\n",
        "\n",
        "def run_analysis(bet, keywords):\n",
        "  file = []\n",
        "  a = Analysis(keywords) # Insert keyword terms in Boolean logic, use '+' between terms\n",
        "  new = a.run()\n",
        "  \n",
        "  # File output and formatting\n",
        "  file.append('Bet: '+ bet + '|')\n",
        "  file.append('Keywords Search: ' + str(a.term) +'|')\n",
        "  file.append('Query Link:' + a.url + '|')\n",
        "  file.append('Subjectivity: '+ str(round(a.subjectivity,5)) + ' Sentiment: ' + str(round(a.sentiment,5))+\"|\")\n",
        "  # Iterate through Analysis object to append results\n",
        "  for row in new:\n",
        "    file.append(row+\"|\")\n",
        "  file.append('\\n----------------------------------------------------------------\\n|')\n",
        "  return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfSYqQoKeCxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run analysis for each bet and output to pickle and csv files\n",
        "for count,bet in enumerate(other_bets):\n",
        "  # Initialize file naming through iterative loop\n",
        "  pkl_filename = (str(bet) + \".pkl\")\n",
        "  csv_filename = (str(bet) + \".csv\")\n",
        "  txt_filename = (str(bet) + \".txt\")\n",
        "  \n",
        "  # Output analysis content to pickle files\n",
        "  analysis_file = run_analysis(bet, keywords[count])\n",
        "  output = open(str(pkl_filename), 'wb')\n",
        "  pickle.dump(analysis_file,output)\n",
        "  output.close()\n",
        "  \n",
        "  # Output the analsis file to csv and screen\n",
        "#   for row in analysis_file:\n",
        "#     print(row)\n",
        " \n",
        "  # CSV output of analysis contents '|' delimited  \n",
        "#   with open(csv_filename) as csvfile:\n",
        "#     read = csv.reader(csvfile , delimiter = '|')\n",
        "#     for row in read:\n",
        "#         print(row)\n",
        "        \n",
        "  # Text file output of analsis contents\n",
        "  with open(txt_filename,\"a\") as f:\n",
        "    for row in analysis_file:\n",
        "      print(row, file=f)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7YnAdMecm-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Examine contents of pickle files\n",
        "for count, bet in enumerate(other_bets):\n",
        "#   pkl_filename = (str(bet)+\".pkl\")\n",
        "#   pickle_in = open(pkl_filename,\"rb\")\n",
        "#   pkl_results = (pickle.load(pickle_in))\n",
        "\n",
        "#   # Print Pickle Results\n",
        "#   for row in pkl_results:\n",
        "#       print(row)\n",
        "      \n",
        "  # Examine contents of CSV files\n",
        "#   csv_filename = (str(bet)+'.csv')      \n",
        "#   with open(csv_filename,\"r\") as f:\n",
        "#     reader = csv.reader(f)\n",
        "#     for row in reader:\n",
        "#         print(row[0].split('|'))\n",
        "        \n",
        "  # Examine contents of Text files\n",
        "  txt_filename = (str(bet)+'.txt')\n",
        "  with open(txt_filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n63NtZRqszy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Output to Google Drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)  \n",
        "\n",
        "# Get the folder id where the file will be saved the\n",
        "# Iterate for all Bet txt files and save results to Google Drive\n",
        "for bet in other_bets:\n",
        "  file = drive.CreateFile({'parents':[{u'id': '1P6JXCfObWODQP5twR9Gz6JZVwY4tyigF'}]})\n",
        "  results_file = str(bet + '.txt')\n",
        "  file.SetContentFile(results_file) \n",
        "  file.Upload() "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}